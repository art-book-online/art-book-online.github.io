{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e743767",
   "metadata": {},
   "source": [
    "# `artlib` Tutorial\n",
    "\n",
    "This is a notebook tutorializing the usage of the `artlib` package!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581d097",
   "metadata": {},
   "source": [
    "## Resources/Links\n",
    "\n",
    "- [Documentation](https://adaptiveresonancelib.readthedocs.io)\n",
    "- [GitHub Repo](https://github.com/NiklasMelton/AdaptiveResonanceLib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459617a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66feb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Init the random seed\n",
    "torch.random.manual_seed(1234)\n",
    "n_samples = 1000\n",
    "\n",
    "def get_mnist(\n",
    "    train: bool = True,\n",
    "    n_samples: int = 1000,\n",
    ") -> DataLoader:\n",
    "    # PyTorch API for combining multiple data transformations steps\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),                      # Tensorize\n",
    "        transforms.Lambda(lambda x: x.view(-1)),    # Flatten\n",
    "    ])\n",
    "\n",
    "    # Download and load the training data\n",
    "    data = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=train,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "    # Wrap the dataset in a DataLoader iterator so that the transform runs\n",
    "    data_loader = DataLoader(data, batch_size=n_samples, shuffle=True)\n",
    "    # Return the data loader\n",
    "    return data_loader\n",
    "\n",
    "# Get the train and test loaders\n",
    "train_loader = get_mnist(True, n_samples)\n",
    "test_loader = get_mnist(False, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9836be",
   "metadata": {},
   "source": [
    "## FuzzyART\n",
    "\n",
    "Set up the FuzzyART module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ebb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from artlib import FuzzyART\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "n_dim = 28*28\n",
    "\n",
    "# Initialize the Fuzzy ART model\n",
    "model = FuzzyART(rho=0.7, alpha = 0.0, beta=1.0)\n",
    "\n",
    "# (Optional) Tell the model the data limits for normalization\n",
    "lower_bounds = np.array([0.]*n_dim)\n",
    "upper_bounds = np.array([1.]*n_dim)\n",
    "model.set_data_bounds(lower_bounds, upper_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c739a",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Train on one mini-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f32f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for x, y in train_loader:\n",
    "    # Preprocess the data (normalize and complement code)\n",
    "    train_X_prep = model.prepare_data(x)\n",
    "    # Fit the model\n",
    "    model.fit(train_X_prep)\n",
    "    # Break early to run just one minibatch for illustration\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68de074",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Test on one mini-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "for x, y in test_loader:\n",
    "    # Preprocess the data (normalize and complement code)\n",
    "    test_X_prep = model.prepare_data(x)\n",
    "    # Predict data labels\n",
    "    predictions = model.predict(test_X_prep)\n",
    "    # Break early to run just one minibatch for illustration\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599eab35",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "See how many categories were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c18497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1000\n",
      "Number of categories: 165\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {n_samples}\")\n",
    "print(f\"Number of categories: {len(np.unique(predictions))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7633af",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "This notebook is a work in progress!\n",
    "If you see this, it means that there is more to come for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b4f0b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "art-book-online",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
